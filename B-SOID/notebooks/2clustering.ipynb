{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "major-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import sys\n",
    "import random\n",
    "sys.path.insert(0, \"D:/IIT/DDP/DDP/B-SOID\")\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from new_clustering import *\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indian-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data/2clustering\"\n",
    "with open(os.path.join(data_dir, \"strainwise_labels.sav\"), \"rb\") as f:\n",
    "    feats, embedding, labels = joblib.load(f)\n",
    "with open(os.path.join(data_dir, \"pairwise_sim.sav\"), \"rb\") as f:\n",
    "    sim, thresh = joblib.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-butter",
   "metadata": {},
   "source": [
    "# Try Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "known-society",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:new_clustering:Strain: 129P3/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: 129S1/SvlmJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: 129X1/SvJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: A/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: AKR/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6129PF1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6129SF1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6AF1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6C3F1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6CBAF1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6D2F1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6SJLF1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: BALB/cByJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: BALB/cJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: BTBR T<+>ltpr3<tf>/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C3H/HeJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C3H/HeOuJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C3HeB/FeJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C57BL/10SnJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C57BL/6J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C57BL/6NJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C57BLKS/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C57BR/cdJ ; Features: (43192, 22) ; Embedding: (43192, 12) ; Labels: (43192,)\n",
      "INFO:new_clustering:Strain: C57L/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C58/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CAF1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CAST/EiJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CB6F1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CBA/CaJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CBA/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CByB6F1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CZECHII/EiJ ; Features: (21596, 22) ; Embedding: (21596, 12) ; Labels: (21596,)\n",
      "INFO:new_clustering:Strain: DBA/1J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: FVB/NJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: I/LnJ ; Features: (48591, 22) ; Embedding: (48591, 12) ; Labels: (48591,)\n",
      "INFO:new_clustering:Strain: NZO/HILtJ ; Features: (5399, 22) ; Embedding: (5399, 12) ; Labels: (5399,)\n",
      "INFO:new_clustering:Strain: DBA/2J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: KK/HiJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: LG/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: LP/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: MA/MyJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: MOLF/EiJ ; Features: (43192, 22) ; Embedding: (43192, 12) ; Labels: (43192,)\n",
      "INFO:new_clustering:Strain: MRL/MpJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: MSM/MsJ ; Features: (16197, 22) ; Embedding: (16197, 12) ; Labels: (16197,)\n",
      "INFO:new_clustering:Strain: NOD/ShiLtJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: NON/ShiLtJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: NOR/LtJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: NU/J ; Features: (10798, 22) ; Embedding: (10798, 12) ; Labels: (10798,)\n",
      "INFO:new_clustering:Strain: NZB/BlNJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: NZW/LacJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: PL/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: PWK/PhJ ; Features: (5399, 22) ; Embedding: (5399, 12) ; Labels: (5399,)\n",
      "INFO:new_clustering:Strain: SM/J ; Features: (48591, 22) ; Embedding: (48591, 12) ; Labels: (48591,)\n",
      "INFO:new_clustering:Strain: WSB/EiJ ; Features: (5399, 22) ; Embedding: (5399, 12) ; Labels: (5399,)\n",
      "INFO:new_clustering:Strain: NZBWF1/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: PWD/PhJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: RIIIS/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: SEA/GnJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: SJL/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: SWR/J ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: TALLYHO/JngJ ; Features: (53990, 22) ; Embedding: (53990, 12) ; Labels: (53990,)\n",
      "INFO:new_clustering:pooling 39 clusters from 129P3/J with entropy ratio 0.9368466864762711\n",
      "INFO:new_clustering:pooling 57 clusters from 129S1/SvlmJ with entropy ratio 0.9448555408750117\n",
      "INFO:new_clustering:pooling 3 clusters from 129X1/SvJ with entropy ratio 0.6326129296753578\n",
      "INFO:new_clustering:pooling 28 clusters from AKR/J with entropy ratio 0.6778269234786407\n",
      "INFO:new_clustering:pooling 19 clusters from B6129PF1/J with entropy ratio 0.7128565675503827\n",
      "INFO:new_clustering:pooling 37 clusters from B6129SF1/J with entropy ratio 0.9503090760248815\n",
      "INFO:new_clustering:pooling 34 clusters from B6AF1/J with entropy ratio 0.9504081097931297\n",
      "INFO:new_clustering:pooling 11 clusters from B6C3F1/J with entropy ratio 0.758477232046511\n",
      "INFO:new_clustering:pooling 24 clusters from B6D2F1/J with entropy ratio 0.9600910402634995\n",
      "INFO:new_clustering:pooling 29 clusters from B6SJLF1/J with entropy ratio 0.7766490717470318\n",
      "INFO:new_clustering:pooling 33 clusters from BALB/cJ with entropy ratio 0.9245931849590799\n",
      "INFO:new_clustering:pooling 23 clusters from BTBR T<+>ltpr3<tf>/J with entropy ratio 0.7214458542124562\n",
      "INFO:new_clustering:pooling 15 clusters from C3H/HeJ with entropy ratio 0.701391654031869\n",
      "INFO:new_clustering:pooling 12 clusters from C57BL/10SnJ with entropy ratio 0.67843930389849\n",
      "INFO:new_clustering:pooling 22 clusters from C57BL/6J with entropy ratio 0.7486958578053177\n",
      "INFO:new_clustering:pooling 29 clusters from C57BL/6NJ with entropy ratio 0.9414674922381822\n",
      "INFO:new_clustering:pooling 24 clusters from C57BLKS/J with entropy ratio 0.9577947789855502\n",
      "INFO:new_clustering:pooling 16 clusters from C57BR/cdJ with entropy ratio 0.677912763913243\n",
      "INFO:new_clustering:pooling 47 clusters from CAF1/J with entropy ratio 0.9636684742110121\n",
      "INFO:new_clustering:pooling 10 clusters from CAST/EiJ with entropy ratio 0.7409831544961771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:new_clustering:pooling 24 clusters from CB6F1/J with entropy ratio 0.9571596173349464\n",
      "INFO:new_clustering:pooling 33 clusters from CBA/CaJ with entropy ratio 0.9331836210293518\n",
      "INFO:new_clustering:pooling 41 clusters from CBA/J with entropy ratio 0.9568402811531074\n",
      "INFO:new_clustering:pooling 29 clusters from CByB6F1/J with entropy ratio 0.9333462730131035\n",
      "INFO:new_clustering:pooling 65 clusters from CZECHII/EiJ with entropy ratio 0.9661655802182814\n",
      "INFO:new_clustering:pooling 16 clusters from DBA/1J with entropy ratio 0.6279957381926006\n",
      "INFO:new_clustering:pooling 38 clusters from DBA/2J with entropy ratio 0.9524914122606575\n",
      "INFO:new_clustering:pooling 5 clusters from FVB/NJ with entropy ratio 0.9399498293294577\n",
      "INFO:new_clustering:pooling 52 clusters from I/LnJ with entropy ratio 0.9312728323399928\n",
      "INFO:new_clustering:pooling 20 clusters from KK/HiJ with entropy ratio 0.7708926536941607\n",
      "INFO:new_clustering:pooling 25 clusters from LG/J with entropy ratio 0.8918462878242392\n",
      "INFO:new_clustering:pooling 50 clusters from LP/J with entropy ratio 0.881588483443669\n",
      "INFO:new_clustering:pooling 33 clusters from MA/MyJ with entropy ratio 0.9613553110157501\n",
      "INFO:new_clustering:pooling 53 clusters from MOLF/EiJ with entropy ratio 0.9540962627232243\n",
      "INFO:new_clustering:pooling 57 clusters from MSM/MsJ with entropy ratio 0.9466648559946487\n",
      "INFO:new_clustering:pooling 13 clusters from NOD/ShiLtJ with entropy ratio 0.7138384833102422\n",
      "INFO:new_clustering:pooling 26 clusters from NON/ShiLtJ with entropy ratio 0.8866770224740296\n",
      "INFO:new_clustering:pooling 14 clusters from NOR/LtJ with entropy ratio 0.6507008546003743\n",
      "INFO:new_clustering:pooling 57 clusters from NU/J with entropy ratio 0.9749347489402221\n",
      "INFO:new_clustering:pooling 47 clusters from NZB/BlNJ with entropy ratio 0.8842432908808591\n",
      "INFO:new_clustering:pooling 51 clusters from NZBWF1/J with entropy ratio 0.8413623968336417\n",
      "INFO:new_clustering:pooling 47 clusters from NZO/HILtJ with entropy ratio 0.8930018043995329\n",
      "INFO:new_clustering:pooling 34 clusters from NZW/LacJ with entropy ratio 0.8173762079716183\n",
      "INFO:new_clustering:pooling 24 clusters from PL/J with entropy ratio 0.9451106508119642\n",
      "INFO:new_clustering:pooling 10 clusters from PWD/PhJ with entropy ratio 0.8553878284827344\n",
      "INFO:new_clustering:pooling 19 clusters from RIIIS/J with entropy ratio 0.9305245456140635\n",
      "INFO:new_clustering:pooling 12 clusters from SEA/GnJ with entropy ratio 0.9262199703454963\n",
      "INFO:new_clustering:pooling 18 clusters from SJL/J with entropy ratio 0.9810978530632337\n",
      "INFO:new_clustering:pooling 30 clusters from SM/J with entropy ratio 0.9664621289136871\n",
      "INFO:new_clustering:pooling 10 clusters from SWR/J with entropy ratio 0.8172403727936652\n",
      "INFO:new_clustering:pooling 25 clusters from TALLYHO/JngJ with entropy ratio 0.9622258417540185\n",
      "INFO:new_clustering:pooling 55 clusters from WSB/EiJ with entropy ratio 0.9519280825991626\n"
     ]
    }
   ],
   "source": [
    "clusters = collect_strainwise_clusters(feats, labels, embedding, thresh=0.6)\n",
    "\n",
    "strain2idx = {}\n",
    "for cluster_idx in clusters.keys():\n",
    "    strain = cluster_idx.split(':')[0]\n",
    "    if strain in strain2idx:\n",
    "        strain2idx[strain].append(cluster_idx)\n",
    "    else:\n",
    "        strain2idx[strain] = [cluster_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hearing-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_similarity(cluster1, cluster2):\n",
    "    X = [cluster1[\"feats\"], cluster2[\"feats\"]]\n",
    "    y = [np.zeros((X[0].shape[0])), np.zeros((X[1].shape[0]))]\n",
    "    \n",
    "    X, y = np.vstack(X), np.hstack(y)\n",
    "    idx = np.random.permutation(np.arange(X.shape[0]))\n",
    "    X, y = X[idx], y[idx]\n",
    "    \n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    model.transform(X).reshape(1,-1)\n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "    return roc_auc_score(y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "planned-completion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_random_strain(thresh):\n",
    "    while True:\n",
    "        strain = random.sample(list(strain2idx.keys()), 1)[0]\n",
    "        X = [clusters[cluster_idx][\"feats\"] for cluster_idx in strain2idx[strain]]\n",
    "        y = [i * np.ones((x.shape[0],)) for i, x in enumerate(X)]\n",
    "        X, y = np.vstack(X), np.hstack(y)\n",
    "        counts = np.unique(y, return_counts=True)[1]\n",
    "        prop = [x / y.size for x in counts]\n",
    "        entropy_ratio = -sum(p * np.log2(p) for p in prop) / max_entropy(len(prop))\n",
    "        if entropy_ratio >= thresh:\n",
    "            print(f\"found: {strain} with entropy: {entropy_ratio}\")\n",
    "            break\n",
    "    \n",
    "    mapper = umap.UMAP(min_dist=0.0, n_neighbors=500, n_components=2, densmap=True).fit(StandardScaler().fit_transform(X))\n",
    "    embed = mapper.embedding_\n",
    "    _, _, glabels, _ = cluster_with_hdbscan(embed, [0.5, 1.0, 11], {\"prediction_data\": True, \"min_samples\": 1})\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(embed[:,0], embed[:,1], c=glabels, cmap=\"Spectral\", s=0.2, alpha=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-cisco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found: CZECHII/EiJ with entropy: 0.9661655802182814\n"
     ]
    }
   ],
   "source": [
    "plot_random_strain(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-means",
   "metadata": {},
   "source": [
    "# Trim identified clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy_ratio_for_strain(strain, clusters):\n",
    "    counts = []\n",
    "    for cluster_id, data in clusters.items():\n",
    "        if cluster_id.split(':')[0] == strain:\n",
    "            counts.append(data[\"feats\"].shape[0])\n",
    "    \n",
    "    prop = [x / sum(counts) for x in counts]\n",
    "    entropy_ratio = -sum(p * np.log2(p) for p in prop) / max_entropy(len(counts))\n",
    "\n",
    "    return entropy_ratio\n",
    "\n",
    "def trim_clusters(clusters, sim_mat, thresh):\n",
    "    # find strains below threshold\n",
    "    strains = list(set([cluster_id.split(':')[0] for cluster_id in clusters.keys()]))\n",
    "    remove_strains = [strain for strain in strains if get_entropy_ratio_for_strain(strain, clusters) < thresh]\n",
    "    \n",
    "    # find cluster idxs to be retained/removed\n",
    "    retain_k, retain_cluster_ids = [], []\n",
    "    for cluster_id in clusters.keys():\n",
    "        strain, _, k = cluster_id.split(':')\n",
    "        if strain not in remove_strains:\n",
    "            retain_k.append(int(k))\n",
    "            retain_cluster_ids.append(cluster_id)\n",
    "    \n",
    "    print(f\"Retained {len(retain_cluster_ids)} out of {len(clusters)} clusters\")\n",
    "    \n",
    "    sim_mat = sim_mat[:,retain_k]\n",
    "    sim_mat = sim_mat[retain_k,:]\n",
    "    \n",
    "    idxmap = {k: i for i, k in enumerate(sorted(retain_k))}\n",
    "    clusters = {cluster_id: clusters[cluster_id] for cluster_id in retain_cluster_ids}\n",
    "    new_clusters = {}\n",
    "    for cluster_id, data in clusters.items():\n",
    "        strain, idx, k = cluster_id.split(':')\n",
    "        new_clusters[f\"{strain}:{idx}:{idxmap[int(k)]}\"] = data\n",
    "\n",
    "    return sim_mat, new_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-safety",
   "metadata": {},
   "source": [
    "# Grouping Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_and_group_clusters(sim_mat):\n",
    "    mapper = umap.UMAP(min_dist=0.0, n_neighbors=50, n_components=2).fit(sim_mat)\n",
    "    assgn, _, glabels, _ = cluster_with_hdbscan(mapper.embedding_, [1.5, 3], HDBSCAN_PARAMS)\n",
    "    \n",
    "    embed = mapper.embedding_[assgn >= 0]\n",
    "    plt.scatter(embed[:,0], embed[:,1], c=glabels[assgn >= 0], s=5, cmap=\"Spectral\")\n",
    "    plt.show()\n",
    "    \n",
    "    return glabels\n",
    "\n",
    "def same_strain_grouping_frac(glabels, clusters):\n",
    "    cluster2group = {k: lab for k, lab in enumerate(glabels)}\n",
    "    group_frac = {}\n",
    "    for cluster_id in clusters.keys():\n",
    "        strain, _, k = cluster_id.split(':')\n",
    "        if strain in group_frac:\n",
    "            group_frac[strain].append(cluster2group[int(k)])\n",
    "        else:\n",
    "            group_frac[strain] = [cluster2group[int(k)]]\n",
    "    group_frac = {strain: round(np.unique(labs).size / len(labs), 2) for strain, labs in group_frac.items()}\n",
    "    return group_frac\n",
    "\n",
    "def avg_group_sim(glabels, clusters, sim_mat):\n",
    "    group_sim = {}\n",
    "    for k, lab in enumerate(glabels):\n",
    "        if lab in group_sim:\n",
    "            group_sim[lab].append(k)\n",
    "        else:\n",
    "            group_sim[lab] = [k]\n",
    "    \n",
    "    within_group_sim = {}\n",
    "    for group, cluster_idx in group_sim.items():\n",
    "        within_group_sim[group] = np.array([sim_mat[i,j] for i, j in combinations(cluster_idx, 2)]).mean()\n",
    "    \n",
    "    n = glabels.max() + 1\n",
    "    between_group_sim = np.zeros((n, n))\n",
    "    for i, j in combinations(list(group_sim.keys()), 2):\n",
    "        avg_sim = []\n",
    "        for cluster1 in group_sim[i]:\n",
    "            for cluster2 in group_sim[j]:\n",
    "                avg_sim.append(sim_mat[cluster1, cluster2])\n",
    "        between_group_sim[i,j] = between_group_sim[j,i] = np.array(avg_sim).mean()\n",
    "    \n",
    "    between_group_sim = np.abs(between_group_sim - 0.5) + 0.5\n",
    "    return within_group_sim, between_group_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-benjamin",
   "metadata": {},
   "source": [
    "## w/o NN imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-extraction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clusters = collect_strainwise_clusters(feats, labels, embedding, thresh)\n",
    "tsim, tclusters = trim_clusters(clusters, similarity_matrix(sim), thresh=0.5)\n",
    "no_impute_glabs = embed_and_group_clusters(tsim)\n",
    "no_impute_group_frac = same_strain_grouping_frac(no_impute_glabs, tclusters)\n",
    "no_impute_wgs, no_impute_bgs = avg_group_sim(no_impute_glabs, tclusters, tsim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-pleasure",
   "metadata": {},
   "source": [
    "## w/ NN imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = collect_strainwise_clusters(feats, labels, embedding, thresh)\n",
    "imputing_sim = impute_same_strain_values(sim, clusters)\n",
    "impute_tsim, impute_tclusters = trim_clusters(clusters, similarity_matrix(imputing_sim), thresh=0.5)\n",
    "impute_glabs = embed_and_group_clusters(impute_tsim)\n",
    "impute_group_frac = same_strain_grouping_frac(impute_glabs, impute_tclusters)\n",
    "impute_wgs, impute_bgs = avg_group_sim(impute_glabs, impute_tclusters, impute_tsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_frac = {\"strain\": [], \"type\": [], \"frac\": []}\n",
    "for strain in impute_group_frac.keys():\n",
    "    group_frac[\"strain\"].extend([strain, strain])\n",
    "    group_frac[\"type\"].append(\"impute\")\n",
    "    group_frac[\"frac\"].append(impute_group_frac[strain])\n",
    "    group_frac[\"type\"].append(\"no impute\")\n",
    "    group_frac[\"frac\"].append(no_impute_group_frac[strain])\n",
    "group_frac = pd.DataFrame.from_dict(group_frac)\n",
    "\n",
    "plt.figure(figsize=(5, 10))\n",
    "sns.barplot(x=\"frac\", y=\"strain\", hue=\"type\", data=group_frac)\n",
    "plt.plot([0.5, 0.5], plt.ylim(), \"--\", c=\"0.8\")\n",
    "plt.title(\"Strainwise Grouping Fraction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "axs[0][0].barh(list(no_impute_wgs.keys()), [x for _, x in no_impute_wgs.items()])\n",
    "axs[0][0].plot([0.5, 0.5], axs[0][0].get_ylim(), '--', color='0.8')\n",
    "axs[1][0].barh(list(impute_wgs.keys()), [x for _, x in impute_wgs.items()])\n",
    "axs[1][0].plot([0.5, 0.5], axs[1][0].get_ylim(), '--', color='0.8')\n",
    "sns.heatmap(no_impute_bgs, ax=axs[0][1])\n",
    "sns.heatmap(impute_bgs, ax=axs[1][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = similarity_matrix(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imshow(\"heatmap\", M)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "n = 22\n",
    "centers = np.vstack((np.zeros(2,), np.ones(2,)))\n",
    "X, y = make_blobs([2000, 500], n, centers=centers, cluster_std=1, shuffle=True)\n",
    "model = LinearDiscriminantAnalysis().fit(X,y)\n",
    "Xproj = model.transform(X)\n",
    "\n",
    "plt.scatter(Xproj, np.zeros_like(Xproj), c=y, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-korea",
   "metadata": {},
   "source": [
    "# Cluster Data with Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction import extract_data_from_video\n",
    "\n",
    "bsoid = BSOID(\"../config/config.yaml\")\n",
    "video_dir = \"../../../data/videos\"\n",
    "video_files = sorted([os.path.join(video_dir, f) for f in os.listdir(video_dir) if f.endswith(\".avi\")])\n",
    "raw_files = sorted([os.path.join(video_dir, f) for f in os.listdir(video_dir) if f.endswith(\".h5\")])\n",
    "\n",
    "video_data = [extract_data_from_video(bsoid, raw_file, video_file) for raw_file, video_file in zip(raw_files, video_files)]\n",
    "for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
