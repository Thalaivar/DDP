{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "major-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import sys\n",
    "import random\n",
    "sys.path.insert(0, \"D:/IIT/DDP/DDP/B-SOID\")\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from new_clustering import *\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indian-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data/2clustering\"\n",
    "with open(os.path.join(data_dir, \"strainwise_labels.sav\"), \"rb\") as f:\n",
    "    feats, embedding, labels = joblib.load(f)\n",
    "with open(os.path.join(data_dir, \"pairwise_sim.sav\"), \"rb\") as f:\n",
    "    sim, thresh = joblib.load(f)\n",
    "feats = collect_strainwise_feats(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-butter",
   "metadata": {},
   "source": [
    "# Try Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "known-society",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:new_clustering:Strain: 129P3/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: 129S1/SvlmJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: 129X1/SvJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: A/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: AKR/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6129PF1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6129SF1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6AF1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6C3F1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6CBAF1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6D2F1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: B6SJLF1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: BALB/cByJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: BALB/cJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: BTBR T<+>ltpr3<tf>/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C3H/HeJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C3H/HeOuJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C3HeB/FeJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C57BL/10SnJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C57BL/6J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C57BL/6NJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C57BLKS/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C57BR/cdJ ; Features: (43192, 56) ; Embedding: (43192, 25) ; Labels: (43192,)\n",
      "INFO:new_clustering:Strain: C57L/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: C58/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CAF1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CAST/EiJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CB6F1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CBA/CaJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CBA/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CByB6F1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: CZECHII/EiJ ; Features: (21596, 56) ; Embedding: (21596, 25) ; Labels: (21596,)\n",
      "INFO:new_clustering:Strain: DBA/1J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: DBA/2J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: FVB/NJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: I/LnJ ; Features: (48591, 56) ; Embedding: (48591, 25) ; Labels: (48591,)\n",
      "INFO:new_clustering:Strain: KK/HiJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: LG/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: LP/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: MA/MyJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: MOLF/EiJ ; Features: (43192, 56) ; Embedding: (43192, 25) ; Labels: (43192,)\n",
      "INFO:new_clustering:Strain: MRL/MpJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: MSM/MsJ ; Features: (16197, 56) ; Embedding: (16197, 25) ; Labels: (16197,)\n",
      "INFO:new_clustering:Strain: NOD/ShiLtJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: NON/ShiLtJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: NOR/LtJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: NU/J ; Features: (10798, 56) ; Embedding: (10798, 25) ; Labels: (10798,)\n",
      "INFO:new_clustering:Strain: NZB/BlNJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: NZBWF1/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: NZO/HILtJ ; Features: (5399, 56) ; Embedding: (5399, 25) ; Labels: (5399,)\n",
      "INFO:new_clustering:Strain: NZW/LacJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: PL/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: PWK/PhJ ; Features: (5399, 56) ; Embedding: (5399, 25) ; Labels: (5399,)\n",
      "INFO:new_clustering:Strain: WSB/EiJ ; Features: (5399, 56) ; Embedding: (5399, 25) ; Labels: (5399,)\n",
      "INFO:new_clustering:Strain: PWD/PhJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: RIIIS/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: SEA/GnJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: SJL/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: SM/J ; Features: (48591, 56) ; Embedding: (48591, 25) ; Labels: (48591,)\n",
      "INFO:new_clustering:Strain: SWR/J ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:Strain: TALLYHO/JngJ ; Features: (53990, 56) ; Embedding: (53990, 25) ; Labels: (53990,)\n",
      "INFO:new_clustering:pooling 74 clusters from 129P3/J with entropy ratio 0.9440549053568476\n",
      "INFO:new_clustering:pooling 72 clusters from 129X1/SvJ with entropy ratio 0.957871915342911\n",
      "INFO:new_clustering:pooling 67 clusters from A/J with entropy ratio 0.9494185968813842\n",
      "INFO:new_clustering:pooling 52 clusters from AKR/J with entropy ratio 0.9171774007744945\n",
      "INFO:new_clustering:pooling 44 clusters from B6129PF1/J with entropy ratio 0.9191769424629994\n",
      "INFO:new_clustering:pooling 53 clusters from B6129SF1/J with entropy ratio 0.9440306396855512\n",
      "INFO:new_clustering:pooling 29 clusters from B6CBAF1/J with entropy ratio 0.9753402747813328\n",
      "INFO:new_clustering:pooling 45 clusters from B6SJLF1/J with entropy ratio 0.9520367264617708\n",
      "INFO:new_clustering:pooling 53 clusters from BALB/cByJ with entropy ratio 0.9281342374087869\n",
      "INFO:new_clustering:pooling 53 clusters from BTBR T<+>ltpr3<tf>/J with entropy ratio 0.94615023175938\n",
      "INFO:new_clustering:pooling 57 clusters from C3H/HeJ with entropy ratio 0.9329749239204406\n",
      "INFO:new_clustering:pooling 40 clusters from C3H/HeOuJ with entropy ratio 0.9279327724634617\n",
      "INFO:new_clustering:pooling 56 clusters from C3HeB/FeJ with entropy ratio 0.941147455148624\n",
      "INFO:new_clustering:pooling 35 clusters from C57BL/10SnJ with entropy ratio 0.9451835925262371\n",
      "INFO:new_clustering:pooling 40 clusters from C57BL/6J with entropy ratio 0.9226643397800387\n",
      "INFO:new_clustering:pooling 31 clusters from C57BLKS/J with entropy ratio 0.9580286280209375\n",
      "INFO:new_clustering:pooling 33 clusters from C57BR/cdJ with entropy ratio 0.9071251566184243\n",
      "INFO:new_clustering:pooling 18 clusters from C57L/J with entropy ratio 0.9691445869033235\n",
      "INFO:new_clustering:pooling 33 clusters from C58/J with entropy ratio 0.9322871928719318\n",
      "INFO:new_clustering:pooling 50 clusters from CAF1/J with entropy ratio 0.9071025092935219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:new_clustering:pooling 37 clusters from CAST/EiJ with entropy ratio 0.9465124692380738\n",
      "INFO:new_clustering:pooling 30 clusters from CB6F1/J with entropy ratio 0.9056915193914004\n",
      "INFO:new_clustering:pooling 37 clusters from CBA/CaJ with entropy ratio 0.9444063896442496\n",
      "INFO:new_clustering:pooling 56 clusters from CBA/J with entropy ratio 0.9570471353303639\n",
      "INFO:new_clustering:pooling 40 clusters from CByB6F1/J with entropy ratio 0.9457929476865081\n",
      "INFO:new_clustering:pooling 64 clusters from CZECHII/EiJ with entropy ratio 0.9283137047167646\n",
      "INFO:new_clustering:pooling 60 clusters from DBA/2J with entropy ratio 0.9494678246000532\n",
      "INFO:new_clustering:pooling 23 clusters from FVB/NJ with entropy ratio 0.9460221991309016\n",
      "INFO:new_clustering:pooling 80 clusters from I/LnJ with entropy ratio 0.9651370890021475\n",
      "INFO:new_clustering:pooling 9 clusters from KK/HiJ with entropy ratio 0.9274716379643939\n",
      "INFO:new_clustering:pooling 60 clusters from LG/J with entropy ratio 0.9322273184814311\n",
      "INFO:new_clustering:pooling 45 clusters from MA/MyJ with entropy ratio 0.9481139976522892\n",
      "INFO:new_clustering:pooling 76 clusters from MOLF/EiJ with entropy ratio 0.9688464766982599\n",
      "INFO:new_clustering:pooling 63 clusters from MRL/MpJ with entropy ratio 0.9611080497809877\n",
      "INFO:new_clustering:pooling 80 clusters from MSM/MsJ with entropy ratio 0.9651148293572362\n",
      "INFO:new_clustering:pooling 37 clusters from NOD/ShiLtJ with entropy ratio 0.952649198324906\n",
      "INFO:new_clustering:pooling 27 clusters from NON/ShiLtJ with entropy ratio 0.9490296613614723\n",
      "INFO:new_clustering:pooling 60 clusters from NU/J with entropy ratio 0.9332929115975188\n",
      "INFO:new_clustering:pooling 73 clusters from NZB/BlNJ with entropy ratio 0.9251246368247693\n",
      "INFO:new_clustering:pooling 60 clusters from NZBWF1/J with entropy ratio 0.9085494877605836\n",
      "INFO:new_clustering:pooling 73 clusters from NZO/HILtJ with entropy ratio 0.9626384812378413\n",
      "INFO:new_clustering:pooling 62 clusters from NZW/LacJ with entropy ratio 0.9497573000643325\n",
      "INFO:new_clustering:pooling 51 clusters from PWD/PhJ with entropy ratio 0.9170956014061695\n",
      "INFO:new_clustering:pooling 75 clusters from SJL/J with entropy ratio 0.9611345088825094\n",
      "INFO:new_clustering:pooling 24 clusters from SM/J with entropy ratio 0.9501157229506184\n",
      "INFO:new_clustering:pooling 16 clusters from SWR/J with entropy ratio 0.9266310875173076\n",
      "INFO:new_clustering:pooling 58 clusters from TALLYHO/JngJ with entropy ratio 0.9372785989593699\n",
      "INFO:new_clustering:pooling 85 clusters from WSB/EiJ with entropy ratio 0.9649933180047415\n"
     ]
    }
   ],
   "source": [
    "clusters = collect_strainwise_clusters(feats, labels, embedding, thresh=0.9)\n",
    "\n",
    "strain2idx = {}\n",
    "for cluster_idx in clusters.keys():\n",
    "    strain = cluster_idx.split(':')[0]\n",
    "    if strain in strain2idx:\n",
    "        strain2idx[strain].append(cluster_idx)\n",
    "    else:\n",
    "        strain2idx[strain] = [cluster_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "@njit\n",
    "def cdist2val(D):\n",
    "    m,n = D.shape\n",
    "    result = 0.0\n",
    "    for i in range(m):\n",
    "        for j in range(i,n):\n",
    "            result += D[i,j]\n",
    "    return result / (m * n)\n",
    "\n",
    "from scipy.spatial.distance import cdist, directed_hausdorff\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "def cluster_similarity(cluster1, cluster2):\n",
    "    X1, X2 = np.copy(cluster1[\"feats\"]), np.copy(cluster2[\"feats\"])\n",
    "    y = np.hstack((np.zeros((X1.shape[0],)), np.ones((X2.shape[0],))))\n",
    "    X = np.vstack((X1, X2))\n",
    "\n",
    "#     model = LinearDiscriminantAnalysis().fit(X, y)\n",
    "#     X1proj, X2proj = model.transform(X1), model.transform(X2)\n",
    "    \n",
    "#     D = cdist(X1proj, X2proj, metric=\"mahalanobis\")\n",
    "    return calinski_harabasz_score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "strain2clusters = {}\n",
    "for clusterid in clusters.keys():\n",
    "    strain = clusterid.split(':')[0]\n",
    "    if strain in strain2clusters:\n",
    "        strain2clusters[strain].append(clusterid)\n",
    "    else:\n",
    "        strain2clusters[strain] = [clusterid]\n",
    "\n",
    "strain = random.sample(list(strain2clusters.keys()), 1)[0]\n",
    "wthin_strain = Parallel(n_jobs=6)(delayed(cluster_similarity)(clusters[clusteridx1], clusters[clusteridx2]) for clusteridx1, clusteridx2 in combinations(strain2clusters[strain], 2)) \n",
    "\n",
    "strain1, strain2 = random.sample(list(strain2clusters.keys()), 2)\n",
    "bween_strain = []\n",
    "for clusteridx1 in strain2clusters[strain1]:\n",
    "    for clusteridx2 in strain2clusters[strain2]:\n",
    "        bween_strain.append(cluster_similarity(clusters[clusteridx1], clusters[clusteridx2]))\n",
    "wthin_strain, bween_strain = np.array(wthin_strain), np.array(bween_strain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(wthin_strain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(bween_strain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-completion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_random_strain(thresh):\n",
    "    while True:\n",
    "        strain = random.sample(list(strain2idx.keys()), 1)[0]\n",
    "        X = [clusters[cluster_idx][\"feats\"] for cluster_idx in strain2idx[strain]]\n",
    "        y = [i * np.ones((x.shape[0],)) for i, x in enumerate(X)]\n",
    "        X, y = np.vstack(X), np.hstack(y)\n",
    "        counts = np.unique(y, return_counts=True)[1]\n",
    "        prop = [x / y.size for x in counts]\n",
    "        entropy_ratio = -sum(p * np.log2(p) for p in prop) / max_entropy(len(prop))\n",
    "        if entropy_ratio >= thresh:\n",
    "            print(f\"found: {strain} with entropy: {entropy_ratio}\")\n",
    "            break\n",
    "    \n",
    "    mapper = umap.UMAP(min_dist=0.0, n_neighbors=500, n_components=2, densmap=True).fit(StandardScaler().fit_transform(X))\n",
    "    embed = mapper.embedding_\n",
    "    _, _, glabels, _ = cluster_with_hdbscan(embed, [0.5, 1.0, 11], {\"prediction_data\": True, \"min_samples\": 1})\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(embed[:,0], embed[:,1], c=glabels, cmap=\"Spectral\", s=0.2, alpha=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_strain(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-means",
   "metadata": {},
   "source": [
    "# Trim identified clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy_ratio_for_strain(strain, clusters):\n",
    "    counts = []\n",
    "    for cluster_id, data in clusters.items():\n",
    "        if cluster_id.split(':')[0] == strain:\n",
    "            counts.append(data[\"feats\"].shape[0])\n",
    "    \n",
    "    prop = [x / sum(counts) for x in counts]\n",
    "    entropy_ratio = -sum(p * np.log2(p) for p in prop) / max_entropy(len(counts))\n",
    "\n",
    "    return entropy_ratio\n",
    "\n",
    "def trim_clusters(clusters, sim_mat, thresh):\n",
    "    # find strains below threshold\n",
    "    strains = list(set([cluster_id.split(':')[0] for cluster_id in clusters.keys()]))\n",
    "    remove_strains = [strain for strain in strains if get_entropy_ratio_for_strain(strain, clusters) < thresh]\n",
    "    \n",
    "    # find cluster idxs to be retained/removed\n",
    "    retain_k, retain_cluster_ids = [], []\n",
    "    for cluster_id in clusters.keys():\n",
    "        strain, _, k = cluster_id.split(':')\n",
    "        if strain not in remove_strains:\n",
    "            retain_k.append(int(k))\n",
    "            retain_cluster_ids.append(cluster_id)\n",
    "    \n",
    "    print(f\"Retained {len(retain_cluster_ids)} out of {len(clusters)} clusters\")\n",
    "    \n",
    "    sim_mat = sim_mat[:,retain_k]\n",
    "    sim_mat = sim_mat[retain_k,:]\n",
    "    \n",
    "    idxmap = {k: i for i, k in enumerate(sorted(retain_k))}\n",
    "    clusters = {cluster_id: clusters[cluster_id] for cluster_id in retain_cluster_ids}\n",
    "    new_clusters = {}\n",
    "    for cluster_id, data in clusters.items():\n",
    "        strain, idx, k = cluster_id.split(':')\n",
    "        new_clusters[f\"{strain}:{idx}:{idxmap[int(k)]}\"] = data\n",
    "\n",
    "    return sim_mat, new_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-safety",
   "metadata": {},
   "source": [
    "# Grouping Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_and_group_clusters(sim_mat):\n",
    "    mapper = umap.UMAP(min_dist=0.0, n_neighbors=50, n_components=2).fit(sim_mat)\n",
    "    assgn, _, glabels, _ = cluster_with_hdbscan(mapper.embedding_, [1.5, 3], HDBSCAN_PARAMS)\n",
    "    \n",
    "    embed = mapper.embedding_[assgn >= 0]\n",
    "    plt.scatter(embed[:,0], embed[:,1], c=glabels[assgn >= 0], s=5, cmap=\"Spectral\")\n",
    "    plt.show(){}\n",
    "    \n",
    "    return glabels\n",
    "\n",
    "def same_strain_grouping_frac(glabels, clusters):\n",
    "    cluster2group = {k: lab for k, lab in enumerate(glabels)}\n",
    "    group_frac = {}\n",
    "    for cluster_id in clusters.keys():\n",
    "        strain, _, k = cluster_id.split(':')\n",
    "        if strain in group_frac:\n",
    "            group_frac[strain].append(cluster2group[int(k)])\n",
    "        else:\n",
    "            group_frac[strain] = [cluster2group[int(k)]]\n",
    "    group_frac = {strain: round(np.unique(labs).size / len(labs), 2) for strain, labs in group_frac.items()}\n",
    "    return group_frac\n",
    "\n",
    "def avg_group_sim(glabels, clusters, sim_mat):\n",
    "    group_sim = {}\n",
    "    for k, lab in enumerate(glabels):\n",
    "        if lab in group_sim:\n",
    "            group_sim[lab].append(k)\n",
    "        else:\n",
    "            group_sim[lab] = [k]\n",
    "    \n",
    "    within_group_sim = {}\n",
    "    for group, cluster_idx in group_sim.items():\n",
    "        within_group_sim[group] = np.array([sim_mat[i,j] for i, j in combinations(cluster_idx, 2)]).mean()\n",
    "    \n",
    "    n = glabels.max() + 1\n",
    "    between_group_sim = np.zeros((n, n))\n",
    "    for i, j in combinations(list(group_sim.keys()), 2):\n",
    "        avg_sim = []\n",
    "        for cluster1 in group_sim[i]:\n",
    "            for cluster2 in group_sim[j]:\n",
    "                avg_sim.append(sim_mat[cluster1, cluster2])\n",
    "        between_group_sim[i,j] = between_group_sim[j,i] = np.array(avg_sim).mean()\n",
    "    \n",
    "    between_group_sim = np.abs(between_group_sim - 0.5) + 0.5\n",
    "    return within_group_sim, between_group_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-benjamin",
   "metadata": {},
   "source": [
    "## w/o NN imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-extraction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clusters = collect_strainwise_clusters(feats, labels, embedding, thresh)\n",
    "tsim, tclusters = trim_clusters(clusters, similarity_matrix(sim), thresh=0.5)\n",
    "no_impute_glabs = embed_and_group_clusters(tsim)\n",
    "no_impute_group_frac = same_strain_grouping_frac(no_impute_glabs, tclusters)\n",
    "no_impute_wgs, no_impute_bgs = avg_group_sim(no_impute_glabs, tclusters, tsim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-pleasure",
   "metadata": {},
   "source": [
    "## w/ NN imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = collect_strainwise_clusters(feats, labels, embedding, thresh)\n",
    "imputing_sim = impute_same_strain_values(sim, clusters)\n",
    "impute_tsim, impute_tclusters = trim_clusters(clusters, similarity_matrix(imputing_sim), thresh=0.5)\n",
    "impute_glabs = embed_and_group_clusters(impute_tsim)\n",
    "impute_group_frac = same_strain_grouping_frac(impute_glabs, impute_tclusters)\n",
    "impute_wgs, impute_bgs = avg_group_sim(impute_glabs, impute_tclusters, impute_tsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_frac = {\"strain\": [], \"type\": [], \"frac\": []}\n",
    "for strain in impute_group_frac.keys():\n",
    "    group_frac[\"strain\"].extend([strain, strain])\n",
    "    group_frac[\"type\"].append(\"impute\")\n",
    "    group_frac[\"frac\"].append(impute_group_frac[strain])\n",
    "    group_frac[\"type\"].append(\"no impute\")\n",
    "    group_frac[\"frac\"].append(no_impute_group_frac[strain])\n",
    "group_frac = pd.DataFrame.from_dict(group_frac)\n",
    "\n",
    "plt.figure(figsize=(5, 10))\n",
    "sns.barplot(x=\"frac\", y=\"strain\", hue=\"type\", data=group_frac)\n",
    "plt.plot([0.5, 0.5], plt.ylim(), \"--\", c=\"0.8\")\n",
    "plt.title(\"Strainwise Grouping Fraction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "axs[0][0].barh(list(no_impute_wgs.keys()), [x for _, x in no_impute_wgs.items()])\n",
    "axs[0][0].plot([0.5, 0.5], axs[0][0].get_ylim(), '--', color='0.8')\n",
    "axs[1][0].barh(list(impute_wgs.keys()), [x for _, x in impute_wgs.items()])\n",
    "axs[1][0].plot([0.5, 0.5], axs[1][0].get_ylim(), '--', color='0.8')\n",
    "sns.heatmap(no_impute_bgs, ax=axs[0][1])\n",
    "sns.heatmap(impute_bgs, ax=axs[1][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = similarity_matrix(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imshow(\"heatmap\", M)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "n = 22\n",
    "centers = np.vstack((np.zeros(2,), np.ones(2,)))\n",
    "X, y = make_blobs([2000, 500], n, centers=centers, cluster_std=1, shuffle=True)\n",
    "model = LinearDiscriminantAnalysis().fit(X,y)\n",
    "Xproj = model.transform(X)\n",
    "\n",
    "plt.scatter(Xproj, np.zeros_like(Xproj), c=y, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped = umap.UMAP(n_components=2, n_neighbors=10, min_dist=0.0, metric=\"precomputed\").fit_transform(sim_mat)\n",
    "labels, _, glabels, _ = cluster_with_hdbscan(mapped, [0.5, 2.5], {\"prediction_data\": True, \"min_samples\": 1})\n",
    "idx, counts = np.unique(glabels, return_counts=True)\n",
    "plt.barh(idx, counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mapped[:,0], mapped[:,1], s=0.5, c=glabels, cmap=\"Set1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "virtual-lemon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1495, 56) (3792, 56) (5287, 56) (5287,)\n"
     ]
    }
   ],
   "source": [
    "strain = random.sample(list(labels.keys()), 1)\n",
    "feats, labels = feats[strain], labels[strain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-watershed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-float",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-success",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
